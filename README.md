# 2022_Stanford_AI_Audit

Credo AI's Submission for Stanford AI Audit Challenge. In this repo, we
recreate aspects of [ProPublica's analysis of COMPAS](https://www.propublica.org/article/how-we-analyzed-the-compas-recidivism-algorithm)
using Credo AI's Responsible AI ecosystem.

All analyses were performed using Credo AI's open-source assessment framework [Lens](https://credoai-lens.readthedocs.io/en/stable/) ([github](https://github.com/credo-ai/credoai_lens)).

[Credo AI](https://www.credo.ai/) is an AI governance company that builds the Responsible AI Platform.
On this platform, users can instantiate _policy packs_ which codify governance requirements for their
AI systems. These governance requirements take the form of:

1. Process evidence requirements (e.g., a document describing a bias mitigation plan)
2. Technical evidence requirements
3. Reporting specifications

The policy pack is created to reflect a Governance need, which could come from internal
organization initiatives, customer demands, or, most importantly, from regulations or standard
put forward by a governing body. These policy packs can also be used to instantiate a particular
auditing methodology, as they are in this case.



